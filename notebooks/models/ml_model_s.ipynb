{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d4b23bf3",
   "metadata": {},
   "source": [
    "# Spread Model (Scaled Features)\n",
    "\n",
    "Scaling features can be important because it ensures that all features contribute equally to the model, preventing features with larger scales from dominatining the learning process. By scaling, the models overall efficiency is enhanced. \n",
    "\n",
    "It is important to note that not all machine learning models require feature scaling. The models that I train and evaluate below are models that do require feature scaling.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2e642672",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Sklearn packages\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import SelectKBest, mutual_info_classif, f_classif, VarianceThreshold, RFE\n",
    "from sklearn.linear_model import LogisticRegression, Lasso\n",
    "from sklearn.preprocessing import RobustScaler, StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Sklearn Model packages\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "97e45ccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3e4a44eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>spread</th>\n",
       "      <th>ou_value</th>\n",
       "      <th>fav_ml_result</th>\n",
       "      <th>fav_sp_result</th>\n",
       "      <th>ou_result</th>\n",
       "      <th>fav_ppg</th>\n",
       "      <th>und_ppg</th>\n",
       "      <th>fav_papg</th>\n",
       "      <th>und_papg</th>\n",
       "      <th>fav_ypg</th>\n",
       "      <th>und_ypg</th>\n",
       "      <th>fav_yapg</th>\n",
       "      <th>und_yapg</th>\n",
       "      <th>fav_topg</th>\n",
       "      <th>und_topg</th>\n",
       "      <th>fav_tofpg</th>\n",
       "      <th>und_tofpg</th>\n",
       "      <th>fav_avg_mov</th>\n",
       "      <th>und_avg_mov</th>\n",
       "      <th>fav_win_pct</th>\n",
       "      <th>und_win_pct</th>\n",
       "      <th>fav_last_5_win_pct</th>\n",
       "      <th>und_last_5_win_pct</th>\n",
       "      <th>fav_home_win_pct</th>\n",
       "      <th>und_home_win_pct</th>\n",
       "      <th>fav_away_win_pct</th>\n",
       "      <th>und_away_win_pct</th>\n",
       "      <th>ppg_diff</th>\n",
       "      <th>ypg_diff</th>\n",
       "      <th>topg_diff</th>\n",
       "      <th>avg_mov_diff</th>\n",
       "      <th>win_pct_diff</th>\n",
       "      <th>last_5_win_pct_diff</th>\n",
       "      <th>team_ovr_diff</th>\n",
       "      <th>ypg_sum</th>\n",
       "      <th>ppg_ratio</th>\n",
       "      <th>ypg_ratio</th>\n",
       "      <th>avg_mov_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-9.5</td>\n",
       "      <td>53.5</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>34.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>369.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>369.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>-14.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.35</td>\n",
       "      <td>729.0</td>\n",
       "      <td>1.70</td>\n",
       "      <td>1.02</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>49.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>25.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>506.0</td>\n",
       "      <td>383.0</td>\n",
       "      <td>383.0</td>\n",
       "      <td>506.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-13.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-13.0</td>\n",
       "      <td>123.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-26.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>889.0</td>\n",
       "      <td>0.66</td>\n",
       "      <td>1.32</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-7.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>381.0</td>\n",
       "      <td>306.0</td>\n",
       "      <td>306.0</td>\n",
       "      <td>381.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>-32.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.31</td>\n",
       "      <td>687.0</td>\n",
       "      <td>6.33</td>\n",
       "      <td>1.25</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-6.5</td>\n",
       "      <td>39.5</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>27.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>404.0</td>\n",
       "      <td>254.0</td>\n",
       "      <td>254.0</td>\n",
       "      <td>404.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>-10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-10.92</td>\n",
       "      <td>658.0</td>\n",
       "      <td>1.59</td>\n",
       "      <td>1.59</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-3.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>34.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>372.0</td>\n",
       "      <td>388.0</td>\n",
       "      <td>388.0</td>\n",
       "      <td>372.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-16.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.89</td>\n",
       "      <td>760.0</td>\n",
       "      <td>1.13</td>\n",
       "      <td>0.96</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   spread  ou_value  fav_ml_result  fav_sp_result  ou_result  fav_ppg  \\\n",
       "0    -9.5      53.5              1            1.0          1     34.0   \n",
       "1    -1.0      49.5              0            0.0          1     25.0   \n",
       "2    -7.0      47.0              1            1.0          0     38.0   \n",
       "3    -6.5      39.5              1            1.0          1     27.0   \n",
       "4    -3.0      48.0              1            1.0          1     34.0   \n",
       "\n",
       "   und_ppg  fav_papg  und_papg  fav_ypg  und_ypg  fav_yapg  und_yapg  \\\n",
       "0     20.0      20.0      34.0    369.0    360.0     360.0     369.0   \n",
       "1     38.0      38.0      25.0    506.0    383.0     383.0     506.0   \n",
       "2      6.0       6.0      38.0    381.0    306.0     306.0     381.0   \n",
       "3     17.0      17.0      27.0    404.0    254.0     254.0     404.0   \n",
       "4     30.0      30.0      34.0    372.0    388.0     388.0     372.0   \n",
       "\n",
       "   fav_topg  und_topg  fav_tofpg  und_tofpg  fav_avg_mov  und_avg_mov  \\\n",
       "0       0.0       1.0        1.0        0.0         14.0        -14.0   \n",
       "1       2.0       0.0        0.0        2.0        -13.0         13.0   \n",
       "2       1.0       3.0        3.0        1.0         32.0        -32.0   \n",
       "3       2.0       2.0        2.0        2.0         10.0        -10.0   \n",
       "4       0.0       0.0        0.0        0.0          4.0         -4.0   \n",
       "\n",
       "   fav_win_pct  und_win_pct  fav_last_5_win_pct  und_last_5_win_pct  \\\n",
       "0          1.0          0.0                 1.0                 0.0   \n",
       "1          0.0          1.0                 0.0                 1.0   \n",
       "2          1.0          0.0                 1.0                 0.0   \n",
       "3          1.0          0.0                 1.0                 0.0   \n",
       "4          1.0          0.0                 1.0                 0.0   \n",
       "\n",
       "   fav_home_win_pct  und_home_win_pct  fav_away_win_pct  und_away_win_pct  \\\n",
       "0               1.0               0.0               0.0               0.0   \n",
       "1               0.0               0.0               0.0               1.0   \n",
       "2               1.0               0.0               0.0               0.0   \n",
       "3               1.0               0.0               0.0               0.0   \n",
       "4               0.0               0.0               1.0               0.0   \n",
       "\n",
       "   ppg_diff  ypg_diff  topg_diff  avg_mov_diff  win_pct_diff  \\\n",
       "0      14.0       9.0       -1.0          28.0           1.0   \n",
       "1     -13.0     123.0        2.0         -26.0          -1.0   \n",
       "2      32.0      75.0       -2.0          64.0           1.0   \n",
       "3      10.0     150.0        0.0          20.0           1.0   \n",
       "4       4.0     -16.0        0.0           8.0           1.0   \n",
       "\n",
       "   last_5_win_pct_diff  team_ovr_diff  ypg_sum  ppg_ratio  ypg_ratio  \\\n",
       "0                  1.0           5.35    729.0       1.70       1.02   \n",
       "1                 -1.0          -1.00    889.0       0.66       1.32   \n",
       "2                  1.0           4.31    687.0       6.33       1.25   \n",
       "3                  1.0         -10.92    658.0       1.59       1.59   \n",
       "4                  1.0          -0.89    760.0       1.13       0.96   \n",
       "\n",
       "   avg_mov_ratio  \n",
       "0           -1.0  \n",
       "1           -1.0  \n",
       "2           -1.0  \n",
       "3           -1.0  \n",
       "4           -1.0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('/Users/epainter/Desktop/bet_model_v2/data/processing/fc_3.csv')\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6e453bd",
   "metadata": {},
   "source": [
    "Here I am dropping the columns that show the result of a game, as we obviously do not want the results of a game to have an effect on our models learning process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "15fec9de",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=['avg_mov_ratio', 'fav_sp_result', 'ou_result'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d47e36b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>spread</th>\n",
       "      <th>ou_value</th>\n",
       "      <th>fav_ml_result</th>\n",
       "      <th>fav_ppg</th>\n",
       "      <th>und_ppg</th>\n",
       "      <th>fav_papg</th>\n",
       "      <th>und_papg</th>\n",
       "      <th>fav_ypg</th>\n",
       "      <th>und_ypg</th>\n",
       "      <th>fav_yapg</th>\n",
       "      <th>und_yapg</th>\n",
       "      <th>fav_topg</th>\n",
       "      <th>und_topg</th>\n",
       "      <th>fav_tofpg</th>\n",
       "      <th>und_tofpg</th>\n",
       "      <th>fav_avg_mov</th>\n",
       "      <th>und_avg_mov</th>\n",
       "      <th>fav_win_pct</th>\n",
       "      <th>und_win_pct</th>\n",
       "      <th>fav_last_5_win_pct</th>\n",
       "      <th>und_last_5_win_pct</th>\n",
       "      <th>fav_home_win_pct</th>\n",
       "      <th>und_home_win_pct</th>\n",
       "      <th>fav_away_win_pct</th>\n",
       "      <th>und_away_win_pct</th>\n",
       "      <th>ppg_diff</th>\n",
       "      <th>ypg_diff</th>\n",
       "      <th>topg_diff</th>\n",
       "      <th>avg_mov_diff</th>\n",
       "      <th>win_pct_diff</th>\n",
       "      <th>last_5_win_pct_diff</th>\n",
       "      <th>team_ovr_diff</th>\n",
       "      <th>ypg_sum</th>\n",
       "      <th>ppg_ratio</th>\n",
       "      <th>ypg_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1071.000000</td>\n",
       "      <td>1071.000000</td>\n",
       "      <td>1071.000000</td>\n",
       "      <td>1071.000000</td>\n",
       "      <td>1071.000000</td>\n",
       "      <td>1071.000000</td>\n",
       "      <td>1071.000000</td>\n",
       "      <td>1071.000000</td>\n",
       "      <td>1071.000000</td>\n",
       "      <td>1071.000000</td>\n",
       "      <td>1071.000000</td>\n",
       "      <td>1071.000000</td>\n",
       "      <td>1071.000000</td>\n",
       "      <td>1071.000000</td>\n",
       "      <td>1071.000000</td>\n",
       "      <td>1071.000000</td>\n",
       "      <td>1071.000000</td>\n",
       "      <td>1071.000000</td>\n",
       "      <td>1071.000000</td>\n",
       "      <td>1071.000000</td>\n",
       "      <td>1071.000000</td>\n",
       "      <td>1071.000000</td>\n",
       "      <td>1071.000000</td>\n",
       "      <td>1071.000000</td>\n",
       "      <td>1071.000000</td>\n",
       "      <td>1071.000000</td>\n",
       "      <td>1071.000000</td>\n",
       "      <td>1071.000000</td>\n",
       "      <td>1071.000000</td>\n",
       "      <td>1071.000000</td>\n",
       "      <td>1071.000000</td>\n",
       "      <td>1071.000000</td>\n",
       "      <td>1071.000000</td>\n",
       "      <td>1071.000000</td>\n",
       "      <td>1071.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-5.305322</td>\n",
       "      <td>45.297386</td>\n",
       "      <td>0.660131</td>\n",
       "      <td>24.761148</td>\n",
       "      <td>21.200710</td>\n",
       "      <td>22.014472</td>\n",
       "      <td>23.962446</td>\n",
       "      <td>361.164659</td>\n",
       "      <td>332.710411</td>\n",
       "      <td>339.669402</td>\n",
       "      <td>354.303940</td>\n",
       "      <td>1.255275</td>\n",
       "      <td>1.342502</td>\n",
       "      <td>1.387348</td>\n",
       "      <td>1.214678</td>\n",
       "      <td>2.891298</td>\n",
       "      <td>-2.899197</td>\n",
       "      <td>0.586797</td>\n",
       "      <td>0.413931</td>\n",
       "      <td>0.589897</td>\n",
       "      <td>0.409589</td>\n",
       "      <td>0.574715</td>\n",
       "      <td>0.416275</td>\n",
       "      <td>0.550682</td>\n",
       "      <td>0.374052</td>\n",
       "      <td>3.560439</td>\n",
       "      <td>28.454248</td>\n",
       "      <td>-0.087227</td>\n",
       "      <td>5.790495</td>\n",
       "      <td>0.172866</td>\n",
       "      <td>0.180308</td>\n",
       "      <td>3.199589</td>\n",
       "      <td>693.875070</td>\n",
       "      <td>1.232661</td>\n",
       "      <td>1.101718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3.499087</td>\n",
       "      <td>4.672252</td>\n",
       "      <td>0.473886</td>\n",
       "      <td>5.281672</td>\n",
       "      <td>4.916604</td>\n",
       "      <td>4.954943</td>\n",
       "      <td>4.672909</td>\n",
       "      <td>44.999518</td>\n",
       "      <td>44.421907</td>\n",
       "      <td>46.045253</td>\n",
       "      <td>41.795514</td>\n",
       "      <td>0.540782</td>\n",
       "      <td>0.510628</td>\n",
       "      <td>0.545258</td>\n",
       "      <td>0.524967</td>\n",
       "      <td>9.237082</td>\n",
       "      <td>8.847268</td>\n",
       "      <td>0.238532</td>\n",
       "      <td>0.249736</td>\n",
       "      <td>0.272655</td>\n",
       "      <td>0.284087</td>\n",
       "      <td>0.319996</td>\n",
       "      <td>0.300247</td>\n",
       "      <td>0.301839</td>\n",
       "      <td>0.310014</td>\n",
       "      <td>6.482080</td>\n",
       "      <td>56.600140</td>\n",
       "      <td>0.745671</td>\n",
       "      <td>11.948868</td>\n",
       "      <td>0.328326</td>\n",
       "      <td>0.378540</td>\n",
       "      <td>8.015640</td>\n",
       "      <td>69.231126</td>\n",
       "      <td>0.456204</td>\n",
       "      <td>0.186415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-20.000000</td>\n",
       "      <td>28.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>142.000000</td>\n",
       "      <td>180.000000</td>\n",
       "      <td>142.000000</td>\n",
       "      <td>163.670000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-40.000000</td>\n",
       "      <td>-32.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-30.000000</td>\n",
       "      <td>-239.000000</td>\n",
       "      <td>-3.000000</td>\n",
       "      <td>-37.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-19.550000</td>\n",
       "      <td>381.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.510000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-7.000000</td>\n",
       "      <td>42.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>21.320000</td>\n",
       "      <td>17.750000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>334.750000</td>\n",
       "      <td>301.710000</td>\n",
       "      <td>311.085000</td>\n",
       "      <td>330.285000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-3.000000</td>\n",
       "      <td>-9.000000</td>\n",
       "      <td>0.440000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.380000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.330000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.250000</td>\n",
       "      <td>-7.715000</td>\n",
       "      <td>-0.500000</td>\n",
       "      <td>-2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-2.650000</td>\n",
       "      <td>646.975000</td>\n",
       "      <td>0.990000</td>\n",
       "      <td>0.980000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-4.000000</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>21.870000</td>\n",
       "      <td>23.920000</td>\n",
       "      <td>362.910000</td>\n",
       "      <td>331.440000</td>\n",
       "      <td>340.000000</td>\n",
       "      <td>354.750000</td>\n",
       "      <td>1.200000</td>\n",
       "      <td>1.330000</td>\n",
       "      <td>1.380000</td>\n",
       "      <td>1.170000</td>\n",
       "      <td>2.670000</td>\n",
       "      <td>-3.000000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.570000</td>\n",
       "      <td>0.330000</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>-0.060000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.170000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>3.130000</td>\n",
       "      <td>694.130000</td>\n",
       "      <td>1.170000</td>\n",
       "      <td>1.090000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>-3.000000</td>\n",
       "      <td>48.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>28.345000</td>\n",
       "      <td>24.120000</td>\n",
       "      <td>24.800000</td>\n",
       "      <td>26.760000</td>\n",
       "      <td>390.035000</td>\n",
       "      <td>362.875000</td>\n",
       "      <td>366.785000</td>\n",
       "      <td>381.000000</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>1.620000</td>\n",
       "      <td>1.690000</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>8.670000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.830000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.570000</td>\n",
       "      <td>7.655000</td>\n",
       "      <td>63.955000</td>\n",
       "      <td>0.280000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>0.340000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>9.080000</td>\n",
       "      <td>737.195000</td>\n",
       "      <td>1.390000</td>\n",
       "      <td>1.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>58.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>44.000000</td>\n",
       "      <td>43.330000</td>\n",
       "      <td>43.000000</td>\n",
       "      <td>44.000000</td>\n",
       "      <td>536.000000</td>\n",
       "      <td>550.330000</td>\n",
       "      <td>536.000000</td>\n",
       "      <td>522.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>32.330000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>259.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>28.450000</td>\n",
       "      <td>948.000000</td>\n",
       "      <td>6.670000</td>\n",
       "      <td>2.040000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            spread     ou_value  fav_ml_result      fav_ppg      und_ppg  \\\n",
       "count  1071.000000  1071.000000    1071.000000  1071.000000  1071.000000   \n",
       "mean     -5.305322    45.297386       0.660131    24.761148    21.200710   \n",
       "std       3.499087     4.672252       0.473886     5.281672     4.916604   \n",
       "min     -20.000000    28.500000       0.000000     0.000000     3.000000   \n",
       "25%      -7.000000    42.000000       0.000000    21.320000    17.750000   \n",
       "50%      -4.000000    45.000000       1.000000    25.000000    21.000000   \n",
       "75%      -3.000000    48.500000       1.000000    28.345000    24.120000   \n",
       "max       1.000000    58.000000       1.000000    44.000000    43.330000   \n",
       "\n",
       "          fav_papg     und_papg      fav_ypg      und_ypg     fav_yapg  \\\n",
       "count  1071.000000  1071.000000  1071.000000  1071.000000  1071.000000   \n",
       "mean     22.014472    23.962446   361.164659   332.710411   339.669402   \n",
       "std       4.954943     4.672909    44.999518    44.421907    46.045253   \n",
       "min       0.000000     6.000000   142.000000   180.000000   142.000000   \n",
       "25%      19.000000    21.000000   334.750000   301.710000   311.085000   \n",
       "50%      21.870000    23.920000   362.910000   331.440000   340.000000   \n",
       "75%      24.800000    26.760000   390.035000   362.875000   366.785000   \n",
       "max      43.000000    44.000000   536.000000   550.330000   536.000000   \n",
       "\n",
       "          und_yapg     fav_topg     und_topg    fav_tofpg    und_tofpg  \\\n",
       "count  1071.000000  1071.000000  1071.000000  1071.000000  1071.000000   \n",
       "mean    354.303940     1.255275     1.342502     1.387348     1.214678   \n",
       "std      41.795514     0.540782     0.510628     0.545258     0.524967   \n",
       "min     163.670000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%     330.285000     1.000000     1.000000     1.000000     1.000000   \n",
       "50%     354.750000     1.200000     1.330000     1.380000     1.170000   \n",
       "75%     381.000000     1.500000     1.620000     1.690000     1.500000   \n",
       "max     522.000000     5.000000     3.000000     4.000000     5.000000   \n",
       "\n",
       "       fav_avg_mov  und_avg_mov  fav_win_pct  und_win_pct  fav_last_5_win_pct  \\\n",
       "count  1071.000000  1071.000000  1071.000000  1071.000000         1071.000000   \n",
       "mean      2.891298    -2.899197     0.586797     0.413931            0.589897   \n",
       "std       9.237082     8.847268     0.238532     0.249736            0.272655   \n",
       "min     -40.000000   -32.000000     0.000000     0.000000            0.000000   \n",
       "25%      -3.000000    -9.000000     0.440000     0.250000            0.400000   \n",
       "50%       2.670000    -3.000000     0.600000     0.400000            0.600000   \n",
       "75%       8.670000     3.000000     0.750000     0.550000            0.800000   \n",
       "max      40.000000    32.330000     1.000000     1.000000            1.000000   \n",
       "\n",
       "       und_last_5_win_pct  fav_home_win_pct  und_home_win_pct  \\\n",
       "count         1071.000000       1071.000000       1071.000000   \n",
       "mean             0.409589          0.574715          0.416275   \n",
       "std              0.284087          0.319996          0.300247   \n",
       "min              0.000000          0.000000          0.000000   \n",
       "25%              0.200000          0.380000          0.200000   \n",
       "50%              0.400000          0.600000          0.400000   \n",
       "75%              0.600000          0.830000          0.600000   \n",
       "max              1.000000          1.000000          1.000000   \n",
       "\n",
       "       fav_away_win_pct  und_away_win_pct     ppg_diff     ypg_diff  \\\n",
       "count       1071.000000       1071.000000  1071.000000  1071.000000   \n",
       "mean           0.550682          0.374052     3.560439    28.454248   \n",
       "std            0.301839          0.310014     6.482080    56.600140   \n",
       "min            0.000000          0.000000   -30.000000  -239.000000   \n",
       "25%            0.330000          0.000000    -0.250000    -7.715000   \n",
       "50%            0.570000          0.330000     3.500000    29.000000   \n",
       "75%            0.750000          0.570000     7.655000    63.955000   \n",
       "max            1.000000          1.000000    32.000000   259.000000   \n",
       "\n",
       "         topg_diff  avg_mov_diff  win_pct_diff  last_5_win_pct_diff  \\\n",
       "count  1071.000000   1071.000000   1071.000000          1071.000000   \n",
       "mean     -0.087227      5.790495      0.172866             0.180308   \n",
       "std       0.745671     11.948868      0.328326             0.378540   \n",
       "min      -3.000000    -37.000000     -1.000000            -1.000000   \n",
       "25%      -0.500000     -2.000000      0.000000             0.000000   \n",
       "50%      -0.060000      6.000000      0.170000             0.200000   \n",
       "75%       0.280000     13.000000      0.340000             0.400000   \n",
       "max       4.000000     64.000000      1.000000             1.000000   \n",
       "\n",
       "       team_ovr_diff      ypg_sum    ppg_ratio    ypg_ratio  \n",
       "count    1071.000000  1071.000000  1071.000000  1071.000000  \n",
       "mean        3.199589   693.875070     1.232661     1.101718  \n",
       "std         8.015640    69.231126     0.456204     0.186415  \n",
       "min       -19.550000   381.000000     0.000000     0.510000  \n",
       "25%        -2.650000   646.975000     0.990000     0.980000  \n",
       "50%         3.130000   694.130000     1.170000     1.090000  \n",
       "75%         9.080000   737.195000     1.390000     1.200000  \n",
       "max        28.450000   948.000000     6.670000     2.040000  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e57babd8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fav_ml_result</th>\n",
       "      <th>fav_avg_mov</th>\n",
       "      <th>fav_win_pct</th>\n",
       "      <th>und_win_pct</th>\n",
       "      <th>fav_last_5_win_pct</th>\n",
       "      <th>und_last_5_win_pct</th>\n",
       "      <th>ppg_diff</th>\n",
       "      <th>ypg_diff</th>\n",
       "      <th>topg_diff</th>\n",
       "      <th>avg_mov_diff</th>\n",
       "      <th>win_pct_diff</th>\n",
       "      <th>last_5_win_pct_diff</th>\n",
       "      <th>team_ovr_diff</th>\n",
       "      <th>ypg_sum</th>\n",
       "      <th>ppg_ratio</th>\n",
       "      <th>ypg_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>14.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.00</td>\n",
       "      <td>9.00</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>28.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.35</td>\n",
       "      <td>729.00</td>\n",
       "      <td>1.70</td>\n",
       "      <td>1.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>-13.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-13.00</td>\n",
       "      <td>123.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>-26.00</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>889.00</td>\n",
       "      <td>0.66</td>\n",
       "      <td>1.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>32.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32.00</td>\n",
       "      <td>75.00</td>\n",
       "      <td>-2.00</td>\n",
       "      <td>64.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.31</td>\n",
       "      <td>687.00</td>\n",
       "      <td>6.33</td>\n",
       "      <td>1.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>10.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.00</td>\n",
       "      <td>150.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>20.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-10.92</td>\n",
       "      <td>658.00</td>\n",
       "      <td>1.59</td>\n",
       "      <td>1.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>4.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.00</td>\n",
       "      <td>-16.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>8.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.89</td>\n",
       "      <td>760.00</td>\n",
       "      <td>1.13</td>\n",
       "      <td>0.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1066</th>\n",
       "      <td>0</td>\n",
       "      <td>-17.00</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>-1.50</td>\n",
       "      <td>-28.62</td>\n",
       "      <td>-0.44</td>\n",
       "      <td>-21.00</td>\n",
       "      <td>-0.31</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>-8.25</td>\n",
       "      <td>684.38</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1067</th>\n",
       "      <td>0</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>11.50</td>\n",
       "      <td>86.25</td>\n",
       "      <td>0.38</td>\n",
       "      <td>9.33</td>\n",
       "      <td>0.38</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>12.55</td>\n",
       "      <td>629.37</td>\n",
       "      <td>1.77</td>\n",
       "      <td>1.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1068</th>\n",
       "      <td>0</td>\n",
       "      <td>6.33</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.8</td>\n",
       "      <td>5.50</td>\n",
       "      <td>38.94</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.26</td>\n",
       "      <td>770.18</td>\n",
       "      <td>1.23</td>\n",
       "      <td>1.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1069</th>\n",
       "      <td>1</td>\n",
       "      <td>-7.33</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.50</td>\n",
       "      <td>46.25</td>\n",
       "      <td>-0.87</td>\n",
       "      <td>1.67</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.6</td>\n",
       "      <td>7.50</td>\n",
       "      <td>688.37</td>\n",
       "      <td>1.48</td>\n",
       "      <td>1.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1070</th>\n",
       "      <td>1</td>\n",
       "      <td>9.67</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.6</td>\n",
       "      <td>-3.24</td>\n",
       "      <td>-40.88</td>\n",
       "      <td>0.12</td>\n",
       "      <td>11.34</td>\n",
       "      <td>-0.07</td>\n",
       "      <td>0.2</td>\n",
       "      <td>-4.00</td>\n",
       "      <td>777.50</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.90</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1071 rows Ã— 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      fav_ml_result  fav_avg_mov  fav_win_pct  und_win_pct  \\\n",
       "0                 1        14.00         1.00         0.00   \n",
       "1                 0       -13.00         0.00         1.00   \n",
       "2                 1        32.00         1.00         0.00   \n",
       "3                 1        10.00         1.00         0.00   \n",
       "4                 1         4.00         1.00         0.00   \n",
       "...             ...          ...          ...          ...   \n",
       "1066              0       -17.00         0.31         0.62   \n",
       "1067              0         0.33         0.69         0.31   \n",
       "1068              0         6.33         0.75         0.56   \n",
       "1069              1        -7.33         0.69         0.25   \n",
       "1070              1         9.67         0.62         0.69   \n",
       "\n",
       "      fav_last_5_win_pct  und_last_5_win_pct  ppg_diff  ypg_diff  topg_diff  \\\n",
       "0                    1.0                 0.0     14.00      9.00      -1.00   \n",
       "1                    0.0                 1.0    -13.00    123.00       2.00   \n",
       "2                    1.0                 0.0     32.00     75.00      -2.00   \n",
       "3                    1.0                 0.0     10.00    150.00       0.00   \n",
       "4                    1.0                 0.0      4.00    -16.00       0.00   \n",
       "...                  ...                 ...       ...       ...        ...   \n",
       "1066                 0.2                 0.4     -1.50    -28.62      -0.44   \n",
       "1067                 0.2                 0.4     11.50     86.25       0.38   \n",
       "1068                 0.8                 0.8      5.50     38.94       0.00   \n",
       "1069                 0.6                 0.0      9.50     46.25      -0.87   \n",
       "1070                 0.8                 0.6     -3.24    -40.88       0.12   \n",
       "\n",
       "      avg_mov_diff  win_pct_diff  last_5_win_pct_diff  team_ovr_diff  ypg_sum  \\\n",
       "0            28.00          1.00                  1.0           5.35   729.00   \n",
       "1           -26.00         -1.00                 -1.0          -1.00   889.00   \n",
       "2            64.00          1.00                  1.0           4.31   687.00   \n",
       "3            20.00          1.00                  1.0         -10.92   658.00   \n",
       "4             8.00          1.00                  1.0          -0.89   760.00   \n",
       "...            ...           ...                  ...            ...      ...   \n",
       "1066        -21.00         -0.31                 -0.2          -8.25   684.38   \n",
       "1067          9.33          0.38                 -0.2          12.55   629.37   \n",
       "1068          0.66          0.19                  0.0          14.26   770.18   \n",
       "1069          1.67          0.44                  0.6           7.50   688.37   \n",
       "1070         11.34         -0.07                  0.2          -4.00   777.50   \n",
       "\n",
       "      ppg_ratio  ypg_ratio  \n",
       "0          1.70       1.02  \n",
       "1          0.66       1.32  \n",
       "2          6.33       1.25  \n",
       "3          1.59       1.59  \n",
       "4          1.13       0.96  \n",
       "...         ...        ...  \n",
       "1066       0.93       0.92  \n",
       "1067       1.77       1.32  \n",
       "1068       1.23       1.11  \n",
       "1069       1.48       1.14  \n",
       "1070       0.89       0.90  \n",
       "\n",
       "[1071 rows x 16 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols = ['fav_ml_result',\n",
    "        'fav_avg_mov', 'fav_win_pct', 'und_win_pct',\n",
    "       'fav_last_5_win_pct', 'und_last_5_win_pct', 'ppg_diff',\n",
    "       'ypg_diff', 'topg_diff', 'avg_mov_diff', 'win_pct_diff',\n",
    "       'last_5_win_pct_diff', 'team_ovr_diff', 'ypg_sum', 'ppg_ratio','ypg_ratio']\n",
    "\n",
    "ml_df = df[cols]\n",
    "\n",
    "ml_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a4e1891",
   "metadata": {},
   "source": [
    "# Feature Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3b95c33",
   "metadata": {},
   "source": [
    "## 1.) Creating Training & Test Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a9f3f602",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((856, 15), (215, 15))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = ml_df.drop(columns=['fav_ml_result'])\n",
    "y = ml_df['fav_ml_result']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)\n",
    "\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "527fd10e",
   "metadata": {},
   "source": [
    "# 2.) Basic EDA\n",
    "\n",
    "Before the scaling/feature selection process can begin, I needed to understand each feature in my dataset a bit better. I tried many different plots including boxplots, histograms, and k-density plots to understand each feature. \n",
    "\n",
    "THis is important not only for the assumptions for some of these models, but to understand which type of feature scaling technique to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4ad8417c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/4q/c8tkm_cj1f16_m9nvk_zn4100000gn/T/ipykernel_14573/386750985.py:1: FutureWarning: \n",
      "\n",
      "Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n",
      "\n",
      "  sns.boxplot(y=X_train['ypg_diff'], palette='muted')\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.boxplot(y=X_train['ypg_diff'], palette='muted')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cde57c66",
   "metadata": {},
   "source": [
    "By looking at these features, most of them contain **many** outliers. Thus, it is recommened to use robust scaling, which uses statistics that are robust to outliers such as the median and IQR.\n",
    "\n",
    "A more common approach to scaling is to use standardization, however, this type of feature scaling is **not** robust to outliers as it uses statistics such as the mean and standard deviation which are most certainly affected by outliers.\n",
    "\n",
    "In a later version, I may apply some data imputation to my outliers, but for now I will use both types of feature scaling techniques and evaluate the associated models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaf4745e",
   "metadata": {},
   "source": [
    "# Feature Scaling\n",
    "\n",
    "This step entails scaling both the training and test sets seperately. This prevents data leakage and avoids bias in performance metrics. \n",
    "\n",
    "For example, we do not want the parameters used in scaling the training set to leak into the test set, as our model in the future will be used on new data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f0a7dae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using RobustScaler\n",
    "r_scaler = RobustScaler()\n",
    "X_train_rs = r_scaler.fit_transform(X_train)\n",
    "X_test_rs = r_scaler.transform(X_test)\n",
    "\n",
    "# Using StandardScaler\n",
    "s_scaler = StandardScaler()\n",
    "X_train_ss = s_scaler.fit_transform(X_train)\n",
    "X_test_ss = s_scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1d131c14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert scaled data back into a DataFrame\n",
    "X_train_rs_df =pd.DataFrame(X_train_rs, columns = X.columns)\n",
    "X_test_rs_df =pd.DataFrame(X_test_rs, columns = X.columns)\n",
    "\n",
    "X_train_ss_df = pd.DataFrame(X_train_ss, columns=X.columns)\n",
    "X_test_ss_df =pd.DataFrame(X_test_ss, columns = X.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0a3d7605",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((856, 15), (215, 15), (856, 15), (215, 15))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_rs_df.shape, X_test_rs_df.shape, X_train_ss_df.shape, X_test_ss_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6009b9d5",
   "metadata": {},
   "source": [
    "# Feature Selection\n",
    "\n",
    "Using our scaled training and test sets for both the standard and robust scalers, we can undergo feature selection using the following:\n",
    "\n",
    "In the following cells, I am running 5 different feature importannce techniques. \n",
    "\n",
    "    1. Recursive Feature Elimination\n",
    "    2. Lasso \n",
    "    3. Random Forest\n",
    "    4. Mutual Information\n",
    "    5. ANOVA F-Value\n",
    "\n",
    "For the first 3, I am grouping them together. I have a function *select_features* that applies the 3 feature importance techniques and sorts them in descending order of there importance. \n",
    "\n",
    "For the next 2 (4-5), it selects features based on mutual information and F_values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2a8c9cc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_features(X, y):\n",
    "    \n",
    "    # 1.) Recursive Feature Elimination\n",
    "    rfe_selector = RFE(estimator=LogisticRegression(), n_features_to_select=10, step=1)\n",
    "    rfe_selector = rfe_selector.fit(X, y)\n",
    "    rfe_support = rfe_selector.get_support()\n",
    "    rfe_features = X.loc[:,rfe_support].columns.tolist()\n",
    "    \n",
    "    # 2.) Lasso\n",
    "    lasso = Lasso(alpha=0.1)\n",
    "    lasso.fit(X, y)\n",
    "    lasso_support = lasso.coef_ != 0\n",
    "    lasso_features = X.loc[:,lasso_support].columns.tolist()\n",
    "    \n",
    "    # 3.) Random Forest\n",
    "    rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "    rf.fit(X, y)\n",
    "    rf_features = X.columns[rf.feature_importances_.argsort()[::-1][:10]].tolist()\n",
    "    \n",
    "    # Combine results\n",
    "    feature_selection_df = pd.DataFrame({'Feature': X.columns,\n",
    "                                         'RFE': rfe_support,\n",
    "                                         'Lasso': lasso_support,\n",
    "                                         'RF': rf.feature_importances_})\n",
    "    \n",
    "    # Count the methods that selected each feature\n",
    "    feature_selection_df['Total'] = np.sum(feature_selection_df.iloc[:, 1:], axis=1)\n",
    "    \n",
    "    # Sort with the most important features (selected by most methods) on top\n",
    "    feature_selection_df = feature_selection_df.sort_values('Total', ascending=False)\n",
    "    \n",
    "    return feature_selection_df\n",
    "\n",
    "feature_importance_rs = select_features(X_train_rs_df, y_train)\n",
    "feature_importance_ss = select_features(X_train_ss_df, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec3a8e75",
   "metadata": {},
   "source": [
    "## 1.) Top 5: RFE, Lasso, Random Forest\n",
    "\n",
    "Below I selected the top 5 most important features using the aforementioned feature selection technqiues. I selected the top 5 features using both the robust and standard scalers.\n",
    "\n",
    "Based on the results, the only difference in the top 5 most important features is the 5th most important feature which was *fav_avg_mov* for the robust scaler and it was *ypg_diff* for the standard scaler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "499402a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ppg_diff', 'ypg_diff', 'avg_mov_diff', 'team_ovr_diff', 'ppg_ratio'], dtype='object')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sort features by 'Total' and select top n\n",
    "top_5_features_rs = feature_importance_rs.sort_values('Total', ascending=False)['Feature'].head(5).tolist()\n",
    "\n",
    "# Create a mask for the top 5 features\n",
    "top_5_mask_rs = X_train_rs_df.columns.isin(top_5_features_rs)\n",
    "\n",
    "# Selecting only top n features from training and test sets\n",
    "X_train_rs_top5 = X_train_rs_df.loc[:, top_5_mask_rs]\n",
    "X_test_rs_top5 = X_test_rs_df.loc[:, top_5_mask_rs]\n",
    "\n",
    "X_train_rs_top5.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0395c4bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ppg_diff', 'ypg_diff', 'avg_mov_diff', 'team_ovr_diff', 'ppg_ratio'], dtype='object')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sort features by 'Total' and select top n\n",
    "top_5_features_ss = feature_importance_ss.sort_values('Total', ascending=False)['Feature'].head(5).tolist()\n",
    "\n",
    "# Create a mask for the top 5 features\n",
    "top_5_mask_ss = X_train_ss_df.columns.isin(top_5_features_ss)\n",
    "\n",
    "# Selecting only top n features from training and test sets\n",
    "X_train_ss_top5 = X_train_ss_df.loc[:, top_5_mask_ss]\n",
    "X_test_ss_top5 = X_test_ss_df.loc[:, top_5_mask_ss]\n",
    "\n",
    "X_train_ss_top5.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81bcee7c",
   "metadata": {},
   "source": [
    "## 2.) Mutual Information\n",
    "\n",
    "I did the same as above. I selected the top 5 features based on the mutual classification metric for both the robust and standardized scaled training sets.\n",
    "\n",
    "As we can see, some of the features in these two subsets are shared, but there are some differences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7c6cabda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Index(['fav_avg_mov', 'und_last_5_win_pct', 'ppg_diff', 'ppg_ratio',\n",
       "        'ypg_ratio'],\n",
       "       dtype='object'),\n",
       " Index(['fav_avg_mov', 'und_last_5_win_pct', 'ppg_diff', 'ppg_ratio',\n",
       "        'ypg_ratio'],\n",
       "       dtype='object'))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Robust Scaled Features\n",
    "\n",
    "mi_sel = SelectKBest(mutual_info_classif, k=5)\n",
    "mi_sel.fit(X_train_rs_df, y_train)\n",
    "\n",
    "# Get the indices of the selected features\n",
    "selected_feature_indices = mi_sel.get_support(indices=True)\n",
    "\n",
    "# Get the names of the selected features\n",
    "selected_feature_names = X_train_rs_df.columns[selected_feature_indices]\n",
    "\n",
    "# Create a new DataFrame with only the selected features\n",
    "X_train_rs_mi = pd.DataFrame(mi_sel.transform(X_train_rs_df), \n",
    "                                columns=selected_feature_names, \n",
    "                                index=X_train_rs_df.index)\n",
    "\n",
    "X_test_rs_mi = pd.DataFrame(mi_sel.transform(X_test_rs_df),\n",
    "                        columns=selected_feature_names,\n",
    "                        index=X_test_rs_df.index)\n",
    "\n",
    "X_train_rs_mi.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4b3ec1f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['fav_avg_mov', 'fav_win_pct', 'und_last_5_win_pct', 'ppg_diff',\n",
       "       'ppg_ratio'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Standard Scaled Features\n",
    "\n",
    "mi_sel = SelectKBest(mutual_info_classif, k=5)\n",
    "mi_sel.fit(X_train_ss_df, y_train)\n",
    "\n",
    "# Get the indices of the selected features\n",
    "selected_feature_indices = mi_sel.get_support(indices=True)\n",
    "\n",
    "# Get the names of the selected features\n",
    "selected_feature_names = X_train_ss_df.columns[selected_feature_indices]\n",
    "\n",
    "# Create a new DataFrame with only the selected features\n",
    "X_train_ss_mi = pd.DataFrame(mi_sel.transform(X_train_ss_df), \n",
    "                                columns=selected_feature_names, \n",
    "                                index=X_train_ss_df.index)\n",
    "\n",
    "X_test_ss_mi = pd.DataFrame(mi_sel.transform(X_test_ss_df),\n",
    "                        columns=selected_feature_names,\n",
    "                        index=X_test_ss_df.index)\n",
    "\n",
    "X_train_ss_mi.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "741e6816",
   "metadata": {},
   "source": [
    "## 3.) ANOVA\n",
    "\n",
    "This uses analysis of variance to see which 5 features contribute most to the variability in our response.\n",
    "\n",
    "Based on these results, the features for each subset based on each of the feature scaling techniques were no different."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "47f46495",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['fav_win_pct', 'fav_last_5_win_pct', 'ppg_diff', 'ypg_diff',\n",
       "       'ypg_ratio'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Robust Scaled Features\n",
    "\n",
    "f_sel = SelectKBest(f_classif, k=5)\n",
    "f_sel.fit(X_train_rs_df, y_train)\n",
    "\n",
    "# Get the indices of the selected features\n",
    "selected_feature_indices = f_sel.get_support(indices=True)\n",
    "\n",
    "# Get the names of the selected features\n",
    "selected_feature_names = X_train_rs_df.columns[selected_feature_indices]\n",
    "\n",
    "# Create a new DataFrame with only the selected features\n",
    "X_train_rs_f = pd.DataFrame(f_sel.transform(X_train_rs_df), \n",
    "                                columns=selected_feature_names, \n",
    "                                index=X_train_rs_df.index)\n",
    "\n",
    "X_test_rs_f = pd.DataFrame(f_sel.transform(X_test_rs_df), \n",
    "                                columns=selected_feature_names, \n",
    "                                index=X_test_rs_df.index)\n",
    "\n",
    "X_train_rs_f.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "de347972",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['fav_win_pct', 'fav_last_5_win_pct', 'ppg_diff', 'ypg_diff',\n",
       "       'ypg_ratio'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Standard Scaled Features\n",
    "\n",
    "f_sel = SelectKBest(f_classif, k=5)\n",
    "f_sel.fit(X_train_ss_df, y_train)\n",
    "\n",
    "# Get the indices of the selected features\n",
    "selected_feature_indices = f_sel.get_support(indices=True)\n",
    "\n",
    "# Get the names of the selected features\n",
    "selected_feature_names = X_train_ss_df.columns[selected_feature_indices]\n",
    "\n",
    "# Create a new DataFrame with only the selected features\n",
    "X_train_ss_f = pd.DataFrame(f_sel.transform(X_train_ss_df), \n",
    "                                columns=selected_feature_names, \n",
    "                                index=X_train_ss_df.index)\n",
    "\n",
    "X_test_ss_f = pd.DataFrame(f_sel.transform(X_test_ss_df), \n",
    "                                columns=selected_feature_names, \n",
    "                                index=X_test_ss_df.index)\n",
    "\n",
    "X_train_ss_f.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f10d596c",
   "metadata": {},
   "source": [
    "# Models\n",
    "\n",
    "We will split this into 2 parts. One part for the robust scaled features and the standard scaled features.\n",
    "\n",
    "In each section, we will train each model and evaluate its respective performance. The models are in the order:\n",
    "\n",
    "    1. RFE, Lasso, Random Forest\n",
    "    2. Mutual Information\n",
    "    3. ANOVA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8848de69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define models that require feature scaling\n",
    "models = [\n",
    "    LogisticRegression(random_state=42),\n",
    "    SVC(random_state=42),\n",
    "    GaussianNB(),\n",
    "    KNeighborsClassifier(),\n",
    "    MLPClassifier(random_state=42)\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cca259b5",
   "metadata": {},
   "source": [
    "## 1.) Robust Scaled Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e1ad8fae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "LogisticRegression Results: (RFE, Lasso, Random Forest)\n",
      "Accuracy: 0.6511627906976745\n",
      "Confusion Matrix:\n",
      " [[  0  72]\n",
      " [  3 140]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        72\n",
      "           1       0.66      0.98      0.79       143\n",
      "\n",
      "    accuracy                           0.65       215\n",
      "   macro avg       0.33      0.49      0.39       215\n",
      "weighted avg       0.44      0.65      0.52       215\n",
      "\n",
      "\n",
      "SVC Results: (RFE, Lasso, Random Forest)\n",
      "Accuracy: 0.6651162790697674\n",
      "Confusion Matrix:\n",
      " [[  0  72]\n",
      " [  0 143]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        72\n",
      "           1       0.67      1.00      0.80       143\n",
      "\n",
      "    accuracy                           0.67       215\n",
      "   macro avg       0.33      0.50      0.40       215\n",
      "weighted avg       0.44      0.67      0.53       215\n",
      "\n",
      "\n",
      "GaussianNB Results: (RFE, Lasso, Random Forest)\n",
      "Accuracy: 0.6604651162790698\n",
      "Confusion Matrix:\n",
      " [[ 12  60]\n",
      " [ 13 130]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.48      0.17      0.25        72\n",
      "           1       0.68      0.91      0.78       143\n",
      "\n",
      "    accuracy                           0.66       215\n",
      "   macro avg       0.58      0.54      0.51       215\n",
      "weighted avg       0.62      0.66      0.60       215\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/epainter/Desktop/bet_model_v2/venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/epainter/Desktop/bet_model_v2/venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/epainter/Desktop/bet_model_v2/venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "KNeighborsClassifier Results: (RFE, Lasso, Random Forest)\n",
      "Accuracy: 0.5906976744186047\n",
      "Confusion Matrix:\n",
      " [[ 16  56]\n",
      " [ 32 111]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      0.22      0.27        72\n",
      "           1       0.66      0.78      0.72       143\n",
      "\n",
      "    accuracy                           0.59       215\n",
      "   macro avg       0.50      0.50      0.49       215\n",
      "weighted avg       0.55      0.59      0.57       215\n",
      "\n",
      "\n",
      "MLPClassifier Results: (RFE, Lasso, Random Forest)\n",
      "Accuracy: 0.6465116279069767\n",
      "Confusion Matrix:\n",
      " [[  5  67]\n",
      " [  9 134]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.36      0.07      0.12        72\n",
      "           1       0.67      0.94      0.78       143\n",
      "\n",
      "    accuracy                           0.65       215\n",
      "   macro avg       0.51      0.50      0.45       215\n",
      "weighted avg       0.56      0.65      0.56       215\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/epainter/Desktop/bet_model_v2/venv/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "for model in models:    \n",
    "\n",
    "    # Fit the model\n",
    "    model.fit(X_train_rs_top5, y_train)\n",
    "    \n",
    "    # Predictions using test data\n",
    "    y_pred = model.predict(X_test_rs_top5)\n",
    "    \n",
    "    # Evaluate the model\n",
    "    print(f\"\\n{model.__class__.__name__} Results: (RFE, Lasso, Random Forest)\")\n",
    "    print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "    print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "    print(\"Classification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ce8ce680",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/epainter/Desktop/bet_model_v2/venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/epainter/Desktop/bet_model_v2/venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/epainter/Desktop/bet_model_v2/venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "LogisticRegression Results (Mutual Information):\n",
      "Accuracy: 0.6558139534883721\n",
      "Confusion Matrix:\n",
      " [[  0  72]\n",
      " [  2 141]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        72\n",
      "           1       0.66      0.99      0.79       143\n",
      "\n",
      "    accuracy                           0.66       215\n",
      "   macro avg       0.33      0.49      0.40       215\n",
      "weighted avg       0.44      0.66      0.53       215\n",
      "\n",
      "\n",
      "SVC Results (Mutual Information):\n",
      "Accuracy: 0.6651162790697674\n",
      "Confusion Matrix:\n",
      " [[  0  72]\n",
      " [  0 143]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        72\n",
      "           1       0.67      1.00      0.80       143\n",
      "\n",
      "    accuracy                           0.67       215\n",
      "   macro avg       0.33      0.50      0.40       215\n",
      "weighted avg       0.44      0.67      0.53       215\n",
      "\n",
      "\n",
      "GaussianNB Results (Mutual Information):\n",
      "Accuracy: 0.6558139534883721\n",
      "Confusion Matrix:\n",
      " [[  8  64]\n",
      " [ 10 133]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.44      0.11      0.18        72\n",
      "           1       0.68      0.93      0.78       143\n",
      "\n",
      "    accuracy                           0.66       215\n",
      "   macro avg       0.56      0.52      0.48       215\n",
      "weighted avg       0.60      0.66      0.58       215\n",
      "\n",
      "\n",
      "KNeighborsClassifier Results (Mutual Information):\n",
      "Accuracy: 0.6232558139534884\n",
      "Confusion Matrix:\n",
      " [[ 14  58]\n",
      " [ 23 120]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.38      0.19      0.26        72\n",
      "           1       0.67      0.84      0.75       143\n",
      "\n",
      "    accuracy                           0.62       215\n",
      "   macro avg       0.53      0.52      0.50       215\n",
      "weighted avg       0.58      0.62      0.58       215\n",
      "\n",
      "\n",
      "MLPClassifier Results (Mutual Information):\n",
      "Accuracy: 0.6604651162790698\n",
      "Confusion Matrix:\n",
      " [[  1  71]\n",
      " [  2 141]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      0.01      0.03        72\n",
      "           1       0.67      0.99      0.79       143\n",
      "\n",
      "    accuracy                           0.66       215\n",
      "   macro avg       0.50      0.50      0.41       215\n",
      "weighted avg       0.55      0.66      0.54       215\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/epainter/Desktop/bet_model_v2/venv/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "for model in models:\n",
    "\n",
    "    model.fit(X_train_rs_mi, y_train)\n",
    "    \n",
    "    y_pred = model.predict(X_test_rs_mi)\n",
    "    \n",
    "    print(f\"\\n{model.__class__.__name__} Results (Mutual Information):\")\n",
    "    print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "    print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "    print(\"Classification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "44ff4c1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/epainter/Desktop/bet_model_v2/venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/epainter/Desktop/bet_model_v2/venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/epainter/Desktop/bet_model_v2/venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "LogisticRegression Results: (RFE, Lasso, Random Forest)\n",
      "Accuracy: 0.6604651162790698\n",
      "Confusion Matrix:\n",
      " [[  0  72]\n",
      " [  1 142]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        72\n",
      "           1       0.66      0.99      0.80       143\n",
      "\n",
      "    accuracy                           0.66       215\n",
      "   macro avg       0.33      0.50      0.40       215\n",
      "weighted avg       0.44      0.66      0.53       215\n",
      "\n",
      "\n",
      "SVC Results: (RFE, Lasso, Random Forest)\n",
      "Accuracy: 0.6651162790697674\n",
      "Confusion Matrix:\n",
      " [[  0  72]\n",
      " [  0 143]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        72\n",
      "           1       0.67      1.00      0.80       143\n",
      "\n",
      "    accuracy                           0.67       215\n",
      "   macro avg       0.33      0.50      0.40       215\n",
      "weighted avg       0.44      0.67      0.53       215\n",
      "\n",
      "\n",
      "GaussianNB Results: (RFE, Lasso, Random Forest)\n",
      "Accuracy: 0.6511627906976745\n",
      "Confusion Matrix:\n",
      " [[ 13  59]\n",
      " [ 16 127]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.45      0.18      0.26        72\n",
      "           1       0.68      0.89      0.77       143\n",
      "\n",
      "    accuracy                           0.65       215\n",
      "   macro avg       0.57      0.53      0.51       215\n",
      "weighted avg       0.60      0.65      0.60       215\n",
      "\n",
      "\n",
      "KNeighborsClassifier Results: (RFE, Lasso, Random Forest)\n",
      "Accuracy: 0.6139534883720931\n",
      "Confusion Matrix:\n",
      " [[ 17  55]\n",
      " [ 28 115]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.38      0.24      0.29        72\n",
      "           1       0.68      0.80      0.73       143\n",
      "\n",
      "    accuracy                           0.61       215\n",
      "   macro avg       0.53      0.52      0.51       215\n",
      "weighted avg       0.58      0.61      0.59       215\n",
      "\n",
      "\n",
      "MLPClassifier Results: (RFE, Lasso, Random Forest)\n",
      "Accuracy: 0.6465116279069767\n",
      "Confusion Matrix:\n",
      " [[  1  71]\n",
      " [  5 138]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.17      0.01      0.03        72\n",
      "           1       0.66      0.97      0.78       143\n",
      "\n",
      "    accuracy                           0.65       215\n",
      "   macro avg       0.41      0.49      0.40       215\n",
      "weighted avg       0.49      0.65      0.53       215\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/epainter/Desktop/bet_model_v2/venv/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "for model in models:    \n",
    "\n",
    "    # Fit the model\n",
    "    model.fit(X_train_rs_f, y_train)\n",
    "    \n",
    "    # Predictions using test data\n",
    "    y_pred = model.predict(X_test_rs_f)\n",
    "    \n",
    "    # Evaluate the model\n",
    "    print(f\"\\n{model.__class__.__name__} Results: (ANOVA)\")\n",
    "    print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "    print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "    print(\"Classification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9baccf7",
   "metadata": {},
   "source": [
    "## 2.) Standard Scaled Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e1c44a1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/epainter/Desktop/bet_model_v2/venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/epainter/Desktop/bet_model_v2/venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/epainter/Desktop/bet_model_v2/venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "LogisticRegression Results: (RFE, Lasso, Random Forest)\n",
      "Accuracy: 0.6511627906976745\n",
      "Confusion Matrix:\n",
      " [[  0  72]\n",
      " [  3 140]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        72\n",
      "           1       0.66      0.98      0.79       143\n",
      "\n",
      "    accuracy                           0.65       215\n",
      "   macro avg       0.33      0.49      0.39       215\n",
      "weighted avg       0.44      0.65      0.52       215\n",
      "\n",
      "\n",
      "SVC Results: (RFE, Lasso, Random Forest)\n",
      "Accuracy: 0.6651162790697674\n",
      "Confusion Matrix:\n",
      " [[  0  72]\n",
      " [  0 143]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        72\n",
      "           1       0.67      1.00      0.80       143\n",
      "\n",
      "    accuracy                           0.67       215\n",
      "   macro avg       0.33      0.50      0.40       215\n",
      "weighted avg       0.44      0.67      0.53       215\n",
      "\n",
      "\n",
      "GaussianNB Results: (RFE, Lasso, Random Forest)\n",
      "Accuracy: 0.6604651162790698\n",
      "Confusion Matrix:\n",
      " [[ 12  60]\n",
      " [ 13 130]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.48      0.17      0.25        72\n",
      "           1       0.68      0.91      0.78       143\n",
      "\n",
      "    accuracy                           0.66       215\n",
      "   macro avg       0.58      0.54      0.51       215\n",
      "weighted avg       0.62      0.66      0.60       215\n",
      "\n",
      "\n",
      "KNeighborsClassifier Results: (RFE, Lasso, Random Forest)\n",
      "Accuracy: 0.586046511627907\n",
      "Confusion Matrix:\n",
      " [[ 18  54]\n",
      " [ 35 108]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.34      0.25      0.29        72\n",
      "           1       0.67      0.76      0.71       143\n",
      "\n",
      "    accuracy                           0.59       215\n",
      "   macro avg       0.50      0.50      0.50       215\n",
      "weighted avg       0.56      0.59      0.57       215\n",
      "\n",
      "\n",
      "MLPClassifier Results: (RFE, Lasso, Random Forest)\n",
      "Accuracy: 0.6558139534883721\n",
      "Confusion Matrix:\n",
      " [[  4  68]\n",
      " [  6 137]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.40      0.06      0.10        72\n",
      "           1       0.67      0.96      0.79       143\n",
      "\n",
      "    accuracy                           0.66       215\n",
      "   macro avg       0.53      0.51      0.44       215\n",
      "weighted avg       0.58      0.66      0.56       215\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/epainter/Desktop/bet_model_v2/venv/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "for model in models:    \n",
    "\n",
    "    # Fit the model\n",
    "    model.fit(X_train_ss_top5, y_train)\n",
    "    \n",
    "    # Predictions using test data\n",
    "    y_pred = model.predict(X_test_ss_top5)\n",
    "    \n",
    "    # Evaluate the model\n",
    "    print(f\"\\n{model.__class__.__name__} Results: (RFE, Lasso, Random Forest)\")\n",
    "    print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "    print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "    print(\"Classification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2509f692",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/epainter/Desktop/bet_model_v2/venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/epainter/Desktop/bet_model_v2/venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/epainter/Desktop/bet_model_v2/venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "LogisticRegression Results (Mutual Information):\n",
      "Accuracy: 0.6697674418604651\n",
      "Confusion Matrix:\n",
      " [[  1  71]\n",
      " [  0 143]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.01      0.03        72\n",
      "           1       0.67      1.00      0.80       143\n",
      "\n",
      "    accuracy                           0.67       215\n",
      "   macro avg       0.83      0.51      0.41       215\n",
      "weighted avg       0.78      0.67      0.54       215\n",
      "\n",
      "\n",
      "SVC Results (Mutual Information):\n",
      "Accuracy: 0.6651162790697674\n",
      "Confusion Matrix:\n",
      " [[  0  72]\n",
      " [  0 143]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        72\n",
      "           1       0.67      1.00      0.80       143\n",
      "\n",
      "    accuracy                           0.67       215\n",
      "   macro avg       0.33      0.50      0.40       215\n",
      "weighted avg       0.44      0.67      0.53       215\n",
      "\n",
      "\n",
      "GaussianNB Results (Mutual Information):\n",
      "Accuracy: 0.6558139534883721\n",
      "Confusion Matrix:\n",
      " [[  7  65]\n",
      " [  9 134]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.44      0.10      0.16        72\n",
      "           1       0.67      0.94      0.78       143\n",
      "\n",
      "    accuracy                           0.66       215\n",
      "   macro avg       0.56      0.52      0.47       215\n",
      "weighted avg       0.59      0.66      0.57       215\n",
      "\n",
      "\n",
      "KNeighborsClassifier Results (Mutual Information):\n",
      "Accuracy: 0.6186046511627907\n",
      "Confusion Matrix:\n",
      " [[ 23  49]\n",
      " [ 33 110]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.41      0.32      0.36        72\n",
      "           1       0.69      0.77      0.73       143\n",
      "\n",
      "    accuracy                           0.62       215\n",
      "   macro avg       0.55      0.54      0.54       215\n",
      "weighted avg       0.60      0.62      0.60       215\n",
      "\n",
      "\n",
      "MLPClassifier Results (Mutual Information):\n",
      "Accuracy: 0.6558139534883721\n",
      "Confusion Matrix:\n",
      " [[  2  70]\n",
      " [  4 139]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      0.03      0.05        72\n",
      "           1       0.67      0.97      0.79       143\n",
      "\n",
      "    accuracy                           0.66       215\n",
      "   macro avg       0.50      0.50      0.42       215\n",
      "weighted avg       0.55      0.66      0.54       215\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/epainter/Desktop/bet_model_v2/venv/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "for model in models:\n",
    "\n",
    "    model.fit(X_train_ss_mi, y_train)\n",
    "    \n",
    "    y_pred = model.predict(X_test_ss_mi)\n",
    "    \n",
    "    print(f\"\\n{model.__class__.__name__} Results (Mutual Information):\")\n",
    "    print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "    print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "    print(\"Classification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "18ddc609",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/epainter/Desktop/bet_model_v2/venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/epainter/Desktop/bet_model_v2/venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/epainter/Desktop/bet_model_v2/venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "LogisticRegression Results: (RFE, Lasso, Random Forest)\n",
      "Accuracy: 0.6604651162790698\n",
      "Confusion Matrix:\n",
      " [[  0  72]\n",
      " [  1 142]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        72\n",
      "           1       0.66      0.99      0.80       143\n",
      "\n",
      "    accuracy                           0.66       215\n",
      "   macro avg       0.33      0.50      0.40       215\n",
      "weighted avg       0.44      0.66      0.53       215\n",
      "\n",
      "\n",
      "SVC Results: (RFE, Lasso, Random Forest)\n",
      "Accuracy: 0.6651162790697674\n",
      "Confusion Matrix:\n",
      " [[  0  72]\n",
      " [  0 143]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        72\n",
      "           1       0.67      1.00      0.80       143\n",
      "\n",
      "    accuracy                           0.67       215\n",
      "   macro avg       0.33      0.50      0.40       215\n",
      "weighted avg       0.44      0.67      0.53       215\n",
      "\n",
      "\n",
      "GaussianNB Results: (RFE, Lasso, Random Forest)\n",
      "Accuracy: 0.6511627906976745\n",
      "Confusion Matrix:\n",
      " [[ 13  59]\n",
      " [ 16 127]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.45      0.18      0.26        72\n",
      "           1       0.68      0.89      0.77       143\n",
      "\n",
      "    accuracy                           0.65       215\n",
      "   macro avg       0.57      0.53      0.51       215\n",
      "weighted avg       0.60      0.65      0.60       215\n",
      "\n",
      "\n",
      "KNeighborsClassifier Results: (RFE, Lasso, Random Forest)\n",
      "Accuracy: 0.6093023255813953\n",
      "Confusion Matrix:\n",
      " [[ 17  55]\n",
      " [ 29 114]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.37      0.24      0.29        72\n",
      "           1       0.67      0.80      0.73       143\n",
      "\n",
      "    accuracy                           0.61       215\n",
      "   macro avg       0.52      0.52      0.51       215\n",
      "weighted avg       0.57      0.61      0.58       215\n",
      "\n",
      "\n",
      "MLPClassifier Results: (RFE, Lasso, Random Forest)\n",
      "Accuracy: 0.6465116279069767\n",
      "Confusion Matrix:\n",
      " [[  3  69]\n",
      " [  7 136]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.30      0.04      0.07        72\n",
      "           1       0.66      0.95      0.78       143\n",
      "\n",
      "    accuracy                           0.65       215\n",
      "   macro avg       0.48      0.50      0.43       215\n",
      "weighted avg       0.54      0.65      0.54       215\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/epainter/Desktop/bet_model_v2/venv/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "for model in models:    \n",
    "\n",
    "    # Fit the model\n",
    "    model.fit(X_train_ss_f, y_train)\n",
    "    \n",
    "    # Predictions using test data\n",
    "    y_pred = model.predict(X_test_ss_f)\n",
    "    \n",
    "    # Evaluate the model\n",
    "    print(f\"\\n{model.__class__.__name__} Results: (ANOVA)\")\n",
    "    print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "    print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "    print(\"Classification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fb274db",
   "metadata": {},
   "source": [
    "# Model Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1fd34de",
   "metadata": {},
   "source": [
    "Based on models above we can see that none give us accuracy > 67% (historical NFL favorite win %) which means that these models are not better than guessing for if the favorite will win or not. Based on the performance metrics there are some considerable issues with precision, recall, and f-1 scores. I believe that there are several reasons for this, however the most glaring is that there is a major class imbalance between the 0 & 1 in both the training and test sets. \n",
    "\n",
    "Next steps would be use SMOTE, hyper parameter tuning, and a reconsideration of all of the steps above from feature transformation/scaling and selection to the types of methods used and even the types of models used."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
